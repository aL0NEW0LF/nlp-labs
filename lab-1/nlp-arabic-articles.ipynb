{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from urllib.parse import quote_plus\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer, TreebankWordTokenizer, wordpunct_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import clean\n",
    "import stem\n",
    "import pyarabic.araby as araby\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "import qalsadi.lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News feed container found!\n",
      "Articles links retrieved!\n",
      "Articles titles retrieved!\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d8%a7%d9%84%d8%b3%d9%88%d8%af%d8%a7%d9%86-%d8%aa%d8%b9%d9%84%d9%82-%d8%b9%d9%85%d9%84-%d9%82%d9%86%d9%88%d8%a7%d8%aa-%d8%b9%d8%b1%d8%a8%d9%8a%d8%a9\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d9%84%d8%a3%d9%88%d9%84-%d9%85%d8%b1%d8%a9-%d9%85%d9%86%d8%b0-%d9%86%d9%88%d9%81%d9%85%d8%a8%d8%b1-%d8%b5%d9%88%d8%a7%d8%b1%d9%8a%d8%ae-%d9%85%d9%86-%d9%84%d8%a8%d9%86%d8%a7%d9%86\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d9%82%d8%aa%d9%84%d9%89-%d9%88%d8%ac%d8%b1%d8%ad%d9%89-%d8%a8%d9%87%d8%ac%d9%88%d9%85-%d8%a7%d8%b3%d8%aa%d9%87%d8%af%d9%81-%d8%a5%d9%81%d8%b7%d8%a7%d8%b1%d8%a7-%d8%ac%d9%85%d8%a7%d8%b9%d9%8a%d8%a7\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d8%a7%d9%84%d8%b4%d8%a8%d9%83%d8%a9-%d8%a7%d9%84%d8%b3%d9%88%d8%b1%d9%8a%d8%a9-%d9%84%d8%ad%d9%82%d9%88%d9%82-%d8%a7%d9%84%d8%a5%d9%86%d8%b3%d8%a7%d9%86-%d8%a3%d9%83%d8%ab%d8%b1-%d9%85%d9%86-200\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d8%a7%d9%84%d8%af%d9%88%d9%8a%d8%b1%d9%8a-%d9%8a%d9%83%d8%b4%d9%81-%d9%85%d9%87%d9%85%d8%a9-%d8%a7%d9%84%d9%84%d9%88%d8%a7%d8%a1-%d8%a7%d9%84%d8%b0%d9%8a-%d8%ae%d8%b5%d8%b5%d9%87-%d8%ac%d9%8a%d8%b4\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d8%a2%d9%84%d8%a7%d9%81-%d8%a7%d9%84%d8%a5%d8%b3%d8%b1%d8%a7%d8%a6%d9%8a%d9%84%d9%8a%d9%8a%d9%86-%d9%8a%d8%aa%d8%b8%d8%a7%d9%87%d8%b1%d9%88%d9%86-%d9%84%d9%84%d9%85%d8%b7%d8%a7%d9%84%d8%a8%d8%a9-2\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d8%a7%d8%b3%d8%aa%d8%b4%d9%87%d8%a7%d8%af-%d9%85%d9%82%d8%a7%d8%a6%d8%af-%d8%a8%d9%83%d8%aa%d9%8a%d8%a8%d8%a9-%d8%b7%d9%88%d9%84%d9%83%d8%b1%d9%85-%d8%a8%d8%b1%d8%b5%d8%a7%d8%b5\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%d8%af%d9%88%d9%84-%d8%ba%d8%b1%d8%a8%d9%8a%d8%a9-%d8%a8%d9%8a%d9%86%d9%87%d8%a7-%d8%a7%d9%84%d9%88%d9%84%d8%a7%d9%8a%d8%a7%d8%aa-%d8%a7%d9%84%d9%85%d8%aa%d8%ad%d8%af%d8%a9-%d9%82%d9%84%d9%82%d8%a9\n",
      "Retrieving article content from: https://www.aljazeera.net/news/2024/4/2/%D8%AE%D8%A8%D9%8A%D8%B1-%D8%B9%D8%B3%D9%83%D8%B1%D9%8A-%D9%82%D8%B5%D9%81-%D8%A5%D8%B3%D8%B1%D8%A7%D8%A6%D9%8A%D9%84-%D8%B9%D9%85%D8%A7%D9%84-%D8%A7%D9%84%D8%A5%D8%BA%D8%A7%D8%AB%D8%A9\n",
      "Articles dates retrieved!\n",
      "Articles Contents retrieved!\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://www.aljazeera.net'\n",
    "\n",
    "articles = []\n",
    "articlesTitles = []\n",
    "articlesLinks = []\n",
    "articlesDates = []\n",
    "articlesContents = []\n",
    "\n",
    "html = requests.get(BASE_URL + '/news/').text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "newsFeedContainer = soup.find('section', {'id': 'news-feed-container'})\n",
    "print('News feed container found!')\n",
    "for a in newsFeedContainer.find_all('a', href=True):\n",
    "    articlesLinks.append(a['href'])\n",
    "    articlesTitles.append(a.text)\n",
    "\n",
    "articlesLinks = [(i, l) for i, l in enumerate(articlesLinks) if l.startswith('/news/')]\n",
    "articlesTitles = [t for i, t in enumerate(articlesTitles) if i in [i for i, l in articlesLinks]]\n",
    "articlesLinks = [l for i, l in articlesLinks]\n",
    "\n",
    "print('Articles links retrieved!')\n",
    "print('Articles titles retrieved!')\n",
    "for b in articlesLinks:\n",
    "    url = BASE_URL + b\n",
    "    print('Retrieving article content from: ' + url)\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    article = ''\n",
    "\n",
    "    articleDate = soup.find('span', {'class': 'article-dates__published'}).text\n",
    "\n",
    "    articlesParagraphsContainer = soup.find('div', {'class': 'wysiwyg wysiwyg--all-content css-1vkfgk0'})\n",
    "\n",
    "    articlesParagraphs = articlesParagraphsContainer.find_all('p', recursive=False)\n",
    "\n",
    "    articlesDates.append(articleDate)\n",
    "\n",
    "    for p in articlesParagraphs:\n",
    "        article += p.text + '\\n'\n",
    "\n",
    "    articlesContents.append(article)\n",
    "print('Articles dates retrieved!')\n",
    "print('Articles Contents retrieved!')\n",
    "for i in range(len(articlesTitles)):\n",
    "    articles.append({\n",
    "        'title': articlesTitles[i],\n",
    "        'link': articlesLinks[i],\n",
    "        'date': articlesDates[i],\n",
    "        'content': articlesContents[i]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/aljazzera.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(articles, json_file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "username = quote_plus(os.getenv('MONGODB_USERNAME'))\n",
    "password = quote_plus(os.getenv('MONGODB_PASS'))\n",
    "cluster = os.getenv('MONGODB_CLUSTER_ID')\n",
    "\n",
    "uri = \"mongodb+srv://\" + username + \":\" + password + \"@cluster.\" + cluster + \".mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles inserted successfully\n"
     ]
    }
   ],
   "source": [
    "db = client['nlp-lab-db']\n",
    "\n",
    "collection = db['aljazeera-articles']\n",
    "\n",
    "collection.insert_many(articles)\n",
    "\n",
    "print('Articles inserted successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'السودان يعلّق عمل وسائل إعلام عربية',\n",
       " 'link': '/news/2024/4/2/%d8%a7%d9%84%d8%b3%d9%88%d8%af%d8%a7%d9%86-%d8%aa%d8%b9%d9%84%d9%82-%d8%b9%d9%85%d9%84-%d9%82%d9%86%d9%88%d8%a7%d8%aa-%d8%b9%d8%b1%d8%a8%d9%8a%d8%a9',\n",
       " 'date': '2/4/2024',\n",
       " 'content': 'نقلت وكالة الأنباء الرسمية السودانية عن وزير الإعلام في السودان جراهام عبد القادر قوله إن البلاد علقت، اليوم الثلاثاء، عمل قنوات \"العربية\" و\"الحدث\" و\"سكاي نيوز عربية\"، وذلك \"لعدم التزامها بالمهنية المطلوبة والشفافية، وعدم تجديد تراخيصها\"، حسب تعبيره.\\nونقلت الوكالة عن وزير الثقافة والإعلام أنه أصدر قرارا وزاريا قضى بإيقاف هذه القنوات في السودان.\\nوأضافت أن القرار جاء \"استنادا إلى موجهات ومطلوبات المهنية والشفافية في العمل الإعلامي ومصلحة المواطن السوداني وقيمه، وذلك لعدم التزامها بالشفافية والمهنية المطلوبة، كما أنها لم تجدد تراخيصها لممارسة العمل الإعلامي\".\\n'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tmp/aljazzera.json', 'r', encoding='utf-8') as json_file:\n",
    "    articles = json.load(json_file)\n",
    "    articleExample = articles[0]\n",
    "\n",
    "articleExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\legion\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\legion\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\legion\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['نقلت وكاله الانباء الرسميه السودانيه عن وزير الاعلام في السودان جراهام عبد القادر قوله ان البلاد علقت اليوم الثلاثاء عمل قنوات العربيه والحدث وسكاي نيوز عربيه وذلك لعدم التزامها بالمهنيه المطلوبه والشفافيه وعدم تجديد تراخيصها حسب تعبيره',\n",
       " 'ونقلت الوكاله عن وزير الثقافه والاعلام انه اصدر قرارا وزاريا قضي بايقاف هذه القنوات في السودان',\n",
       " 'واضافت ان القرار جاء استنادا الي موجهات ومطلوبات المهنيه والشفافيه في العمل الاعلامي ومصلحه المواطن السوداني وقيمه وذلك لعدم التزامها بالشفافيه والمهنيه المطلوبه كما انها لم تجدد تراخيصها لممارسه العمل الاعلامي']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paragraphs Tok\n",
    "content = articleExample['content']\n",
    "\n",
    "content = clean.remove_punctuations(content)\n",
    "content = clean.remove_diacritics(content)\n",
    "content = clean.normalize_arabic(content)\n",
    "\n",
    "contentParagraphs = content.split('\\n')\n",
    "\n",
    "contentParagraphs = list(filter(None, contentParagraphs))\n",
    "\n",
    "contentParagraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['نقلت وكاله الانباء الرسميه السودانيه عن وزير الاعلام في السودان جراهام عبد القادر قوله ان البلاد علقت اليوم الثلاثاء عمل قنوات العربيه والحدث وسكاي نيوز عربيه وذلك لعدم التزامها بالمهنيه المطلوبه والشفافيه وعدم تجديد تراخيصها حسب تعبيره']\n",
      "['ونقلت الوكاله عن وزير الثقافه والاعلام انه اصدر قرارا وزاريا قضي بايقاف هذه القنوات في السودان']\n",
      "['واضافت ان القرار جاء استنادا الي موجهات ومطلوبات المهنيه والشفافيه في العمل الاعلامي ومصلحه المواطن السوداني وقيمه وذلك لعدم التزامها بالشفافيه والمهنيه المطلوبه كما انها لم تجدد تراخيصها لممارسه العمل الاعلامي']\n"
     ]
    }
   ],
   "source": [
    "# Sentences Tok\n",
    "for p in contentParagraphs:\n",
    "    sentences = sent_tokenize(p)\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      "['نقلت', 'وكاله', 'الانباء', 'الرسميه', 'السودانيه', 'عن', 'وزير', 'الاعلام', 'في', 'السودان', 'جراهام', 'عبد', 'القادر', 'قوله', 'ان', 'البلاد', 'علقت', 'اليوم', 'الثلاثاء', 'عمل', 'قنوات', 'العربيه', 'والحدث', 'وسكاي', 'نيوز', 'عربيه', 'وذلك', 'لعدم', 'التزامها', 'بالمهنيه', 'المطلوبه', 'والشفافيه', 'وعدم', 'تجديد', 'تراخيصها', 'حسب', 'تعبيره']\n",
      "without stopwords:\n",
      "['نقلت', 'وكاله', 'الانباء', 'الرسميه', 'السودانيه', 'وزير', 'الاعلام', 'السودان', 'جراهام', 'عبد', 'القادر', 'قوله', 'ان', 'البلاد', 'علقت', 'اليوم', 'الثلاثاء', 'عمل', 'قنوات', 'العربيه', 'والحدث', 'وسكاي', 'نيوز', 'عربيه', 'وذلك', 'لعدم', 'التزامها', 'بالمهنيه', 'المطلوبه', 'والشفافيه', 'وعدم', 'تجديد', 'تراخيصها', 'تعبيره']\n",
      "--------------------------------------\n",
      "original:\n",
      "['ونقلت', 'الوكاله', 'عن', 'وزير', 'الثقافه', 'والاعلام', 'انه', 'اصدر', 'قرارا', 'وزاريا', 'قضي', 'بايقاف', 'هذه', 'القنوات', 'في', 'السودان']\n",
      "without stopwords:\n",
      "['ونقلت', 'الوكاله', 'وزير', 'الثقافه', 'والاعلام', 'انه', 'اصدر', 'قرارا', 'وزاريا', 'قضي', 'بايقاف', 'القنوات', 'السودان']\n",
      "--------------------------------------\n",
      "original:\n",
      "['واضافت', 'ان', 'القرار', 'جاء', 'استنادا', 'الي', 'موجهات', 'ومطلوبات', 'المهنيه', 'والشفافيه', 'في', 'العمل', 'الاعلامي', 'ومصلحه', 'المواطن', 'السوداني', 'وقيمه', 'وذلك', 'لعدم', 'التزامها', 'بالشفافيه', 'والمهنيه', 'المطلوبه', 'كما', 'انها', 'لم', 'تجدد', 'تراخيصها', 'لممارسه', 'العمل', 'الاعلامي']\n",
      "without stopwords:\n",
      "['واضافت', 'ان', 'القرار', 'جاء', 'استنادا', 'الي', 'موجهات', 'ومطلوبات', 'المهنيه', 'والشفافيه', 'العمل', 'الاعلامي', 'ومصلحه', 'المواطن', 'السوداني', 'وقيمه', 'وذلك', 'لعدم', 'التزامها', 'بالشفافيه', 'والمهنيه', 'المطلوبه', 'انها', 'تجدد', 'تراخيصها', 'لممارسه', 'العمل', 'الاعلامي']\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Word Tok\n",
    "stop_words = set(stopwords.words('arabic'))\n",
    "contentWords = []\n",
    "\n",
    "for p in contentParagraphs:\n",
    "    words = word_tokenize(p)\n",
    "    print(\"original:\")\n",
    "    print(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    print(\"without stopwords:\")\n",
    "    print(words)\n",
    "    print(\"--------------------------------------\")\n",
    "    contentWords.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['نقلت',\n",
       "  'وكاله',\n",
       "  'انباء',\n",
       "  'رسميه',\n",
       "  'سودانيه',\n",
       "  'وزير',\n",
       "  'اعلام',\n",
       "  'سود',\n",
       "  'جراهام',\n",
       "  'عبد',\n",
       "  'قادر',\n",
       "  'قوله',\n",
       "  'ان',\n",
       "  'بلاد',\n",
       "  'علقت',\n",
       "  'اليوم',\n",
       "  'ثلاثاء',\n",
       "  'عمل',\n",
       "  'قنو',\n",
       "  'عربيه',\n",
       "  'حدث',\n",
       "  'وسكاي',\n",
       "  'نيوز',\n",
       "  'عربيه',\n",
       "  'وذلك',\n",
       "  'لعدم',\n",
       "  'تزام',\n",
       "  'مهنيه',\n",
       "  'مطلوبه',\n",
       "  'شفافيه',\n",
       "  'وعدم',\n",
       "  'تجديد',\n",
       "  'تراخيص',\n",
       "  'تعبيره'],\n",
       " ['ونقلت',\n",
       "  'وكاله',\n",
       "  'وزير',\n",
       "  'ثقافه',\n",
       "  'اعلام',\n",
       "  'انه',\n",
       "  'اصدر',\n",
       "  'قرارا',\n",
       "  'وزار',\n",
       "  'قضي',\n",
       "  'بايقاف',\n",
       "  'قنو',\n",
       "  'سود'],\n",
       " ['واضافت',\n",
       "  'ان',\n",
       "  'قرار',\n",
       "  'جاء',\n",
       "  'استنادا',\n",
       "  'الي',\n",
       "  'موجه',\n",
       "  'ومطلوب',\n",
       "  'مهنيه',\n",
       "  'شفافيه',\n",
       "  'عمل',\n",
       "  'اعلامي',\n",
       "  'ومصلحه',\n",
       "  'مواطن',\n",
       "  'سودا',\n",
       "  'وقيمه',\n",
       "  'وذلك',\n",
       "  'لعدم',\n",
       "  'تزام',\n",
       "  'شفافيه',\n",
       "  'مهنيه',\n",
       "  'مطلوبه',\n",
       "  'انها',\n",
       "  'تجدد',\n",
       "  'تراخيص',\n",
       "  'لممارسه',\n",
       "  'عمل',\n",
       "  'اعلامي']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "contentWordsStemmed1 = []\n",
    "\n",
    "for pw in contentWords:\n",
    "    stemmedWords = stem.light_stem(pw)\n",
    "    contentWordsStemmed1.append(stemmedWords)\n",
    "\n",
    "contentWordsStemmed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['نقلت', 'وكاله', 'الانباء', 'الرسميه', 'السودانيه', 'وزير', 'الاعلام', 'السودان', 'جراهام', 'عبد', 'القادر', 'قوله', 'ان', 'البلاد', 'علقت', 'اليوم', 'الثلاثاء', 'عمل', 'قنوات', 'العربيه', 'والحدث', 'وسكاي', 'نيوز', 'عربيه', 'وذلك', 'لعدم', 'التزامها', 'بالمهنيه', 'المطلوبه', 'والشفافيه', 'وعدم', 'تجديد', 'تراخيصها', 'تعبيره']\n",
      "['ونقلت', 'الوكاله', 'وزير', 'الثقافه', 'والاعلام', 'انه', 'اصدر', 'قرارا', 'وزاريا', 'قضي', 'بايقاف', 'القنوات', 'السودان']\n",
      "['واضافت', 'ان', 'القرار', 'جاء', 'استنادا', 'الي', 'موجهات', 'ومطلوبات', 'المهنيه', 'والشفافيه', 'العمل', 'الاعلامي', 'ومصلحه', 'المواطن', 'السوداني', 'وقيمه', 'وذلك', 'لعدم', 'التزامها', 'بالشفافيه', 'والمهنيه', 'المطلوبه', 'انها', 'تجدد', 'تراخيصها', 'لممارسه', 'العمل', 'الاعلامي']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['نقلت',\n",
       "  'وكاله',\n",
       "  'الانباء',\n",
       "  'الرسميه',\n",
       "  'السودانيه',\n",
       "  'وزير',\n",
       "  'الاعلام',\n",
       "  'السودان',\n",
       "  'جراهام',\n",
       "  'عبد',\n",
       "  'القادر',\n",
       "  'قوله',\n",
       "  'ان',\n",
       "  'البلاد',\n",
       "  'علقت',\n",
       "  'اليوم',\n",
       "  'الثلاثاء',\n",
       "  'عمل',\n",
       "  'قنوات',\n",
       "  'العربيه',\n",
       "  'والحدث',\n",
       "  'وسكاي',\n",
       "  'نيوز',\n",
       "  'عربيه',\n",
       "  'وذلك',\n",
       "  'لعدم',\n",
       "  'التزامها',\n",
       "  'بالمهنيه',\n",
       "  'المطلوبه',\n",
       "  'والشفافيه',\n",
       "  'وعدم',\n",
       "  'تجديد',\n",
       "  'تراخيصها',\n",
       "  'تعبيره'],\n",
       " ['ونقلت',\n",
       "  'الوكاله',\n",
       "  'وزير',\n",
       "  'الثقافه',\n",
       "  'والاعلام',\n",
       "  'انه',\n",
       "  'اصدر',\n",
       "  'قرارا',\n",
       "  'وزاريا',\n",
       "  'قضي',\n",
       "  'بايقاف',\n",
       "  'القنوات',\n",
       "  'السودان'],\n",
       " ['واضافت',\n",
       "  'ان',\n",
       "  'القرار',\n",
       "  'جاء',\n",
       "  'استنادا',\n",
       "  'الي',\n",
       "  'موجهات',\n",
       "  'ومطلوبات',\n",
       "  'المهنيه',\n",
       "  'والشفافيه',\n",
       "  'العمل',\n",
       "  'الاعلامي',\n",
       "  'ومصلحه',\n",
       "  'المواطن',\n",
       "  'السوداني',\n",
       "  'وقيمه',\n",
       "  'وذلك',\n",
       "  'لعدم',\n",
       "  'التزامها',\n",
       "  'بالشفافيه',\n",
       "  'والمهنيه',\n",
       "  'المطلوبه',\n",
       "  'انها',\n",
       "  'تجدد',\n",
       "  'تراخيصها',\n",
       "  'لممارسه',\n",
       "  'العمل',\n",
       "  'الاعلامي']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "contentWordsLemma1 = []\n",
    "\n",
    "for pw in contentWords:\n",
    "    words = [lemmatizer.lemmatize(w) for w in pw]\n",
    "    print(words)\n",
    "    contentWordsLemma1.append(words)\n",
    "\n",
    "contentWordsLemma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['قلت',\n",
       "  'ال',\n",
       "  'انباء',\n",
       "  'رسميه',\n",
       "  'سودانيه',\n",
       "  'زير',\n",
       "  'اعلام',\n",
       "  'سود',\n",
       "  'جراهام',\n",
       "  'عبد',\n",
       "  'قادر',\n",
       "  'قول',\n",
       "  'ان',\n",
       "  'بلاد',\n",
       "  'علق',\n",
       "  'يوم',\n",
       "  'ثلاثاء',\n",
       "  'عمل',\n",
       "  'قنو',\n",
       "  'عربيه',\n",
       "  'حدث',\n",
       "  'سك',\n",
       "  'يوز',\n",
       "  'عرب',\n",
       "  'ذلك',\n",
       "  'عدم',\n",
       "  'تزامه',\n",
       "  'مهنيه',\n",
       "  'مطلوبه',\n",
       "  'شفافيه',\n",
       "  'عدم',\n",
       "  'جديد',\n",
       "  'تراخيص',\n",
       "  'عبير'],\n",
       " ['قلت',\n",
       "  'وكاله',\n",
       "  'زير',\n",
       "  'ثقافه',\n",
       "  'اعلام',\n",
       "  'نه',\n",
       "  'صدر',\n",
       "  'قرار',\n",
       "  'زاري',\n",
       "  'قض',\n",
       "  'ايقاف',\n",
       "  'قنو',\n",
       "  'سود'],\n",
       " ['اضاف',\n",
       "  'ان',\n",
       "  'قرار',\n",
       "  'جاء',\n",
       "  'ستناد',\n",
       "  'لي',\n",
       "  'موجه',\n",
       "  'مطلوب',\n",
       "  'مهنيه',\n",
       "  'شفافيه',\n",
       "  'عمل',\n",
       "  'اعلام',\n",
       "  'مصلح',\n",
       "  'مواطن',\n",
       "  'سودان',\n",
       "  'قيم',\n",
       "  'ذلك',\n",
       "  'عدم',\n",
       "  'تزامه',\n",
       "  'شفافيه',\n",
       "  'مهنيه',\n",
       "  'مطلوبه',\n",
       "  'نه',\n",
       "  'جدد',\n",
       "  'تراخيص',\n",
       "  'ممارس',\n",
       "  'عمل',\n",
       "  'اعلام']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming with araby\n",
    "ArListem = ArabicLightStemmer()\n",
    "\n",
    "contentWordsStemmed2 = []\n",
    "\n",
    "for pw in contentWords:\n",
    "    stemmedWords = [ArListem.light_stem(w) for w in pw]\n",
    "    contentWordsStemmed2.append(stemmedWords)\n",
    "\n",
    "contentWordsStemmed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['نقل',\n",
       "  'كال',\n",
       "  'الانباء',\n",
       "  'الرسميه',\n",
       "  'السودانيه',\n",
       "  'زير',\n",
       "  'الاعلام',\n",
       "  'سود',\n",
       "  'جراهام',\n",
       "  'عبد',\n",
       "  'قادر',\n",
       "  'قول',\n",
       "  'ان',\n",
       "  'بلاد',\n",
       "  'علق',\n",
       "  'يوم',\n",
       "  'ثلاثاء',\n",
       "  'عمل',\n",
       "  'قنو',\n",
       "  'العربيه',\n",
       "  'حدث',\n",
       "  'سك',\n",
       "  'نيوز',\n",
       "  'عرب',\n",
       "  'ذلك',\n",
       "  'عدم',\n",
       "  'التزام',\n",
       "  'بالمهنيه',\n",
       "  'المطلوبه',\n",
       "  'والشفافيه',\n",
       "  'عدم',\n",
       "  'تجديد',\n",
       "  'تراخيصها',\n",
       "  'تعبير'],\n",
       " ['نقل',\n",
       "  'الوكاله',\n",
       "  'زير',\n",
       "  'الثقافه',\n",
       "  'والاعلام',\n",
       "  'نهو',\n",
       "  'صدر',\n",
       "  'قرار',\n",
       "  'وزاري',\n",
       "  'قضة',\n",
       "  'بايقاف',\n",
       "  'قنو',\n",
       "  'سود'],\n",
       " ['واضافت',\n",
       "  'ان',\n",
       "  'قرار',\n",
       "  'جاء',\n",
       "  'استناد',\n",
       "  'ال',\n",
       "  'موجه',\n",
       "  'مطلوب',\n",
       "  'المهنيه',\n",
       "  'والشفافيه',\n",
       "  'عمل',\n",
       "  'الاعلامي',\n",
       "  'مصلح',\n",
       "  'مواطن',\n",
       "  'سودان',\n",
       "  'قيم',\n",
       "  'ذلك',\n",
       "  'عدم',\n",
       "  'التزام',\n",
       "  'بالشفافيه',\n",
       "  'والمهنيه',\n",
       "  'المطلوبه',\n",
       "  'انها',\n",
       "  'تجدد',\n",
       "  'تراخيصها',\n",
       "  'ممارس',\n",
       "  'عمل',\n",
       "  'الاعلامي']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemma with qalsadi\n",
    "lemmer = qalsadi.lemmatizer.Lemmatizer()\n",
    "\n",
    "contentWordsLemma2 = []\n",
    "\n",
    "for pw in contentWords:\n",
    "    words = [lemmer.lemmatize(w) for w in pw]\n",
    "    contentWordsLemma2.append(words)\n",
    "\n",
    "contentWordsLemma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refs\n",
    "Motazsaad, “GitHub - motazsaad/process-arabic-text: Pre-process arabic text (remove diacritics, punctuations and repeating characters),” GitHub. https://github.com/motazsaad/process-arabic-text\n",
    "\n",
    "T. Zerrouki, Tashaphyne, Arabic light stemmer, https://pypi.python.org/pypi/Tashaphyne/0.2\n",
    "\n",
    "T. Zerrouki, Pyarabic, An Arabic language library for Python, https://pypi.python.org/pypi/pyarabic/, 2010\n",
    "\n",
    "T. Zerrouki, Qalsadi, Arabic mophological analyzer Library for python.,  https://pypi.python.org/pypi/qalsadi/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
