{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **LIBRARIES IMPORT**"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-24T12:40:25.900535Z","iopub.status.busy":"2024-05-24T12:40:25.899834Z","iopub.status.idle":"2024-05-24T12:40:44.672873Z","shell.execute_reply":"2024-05-24T12:40:44.671825Z","shell.execute_reply.started":"2024-05-24T12:40:25.900503Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n","Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (2023.12.25)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Collecting peft\n","  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.2.2)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes, peft\n","Successfully installed bitsandbytes-0.43.1 peft-0.11.1\n"]}],"source":["!pip install transformers datasets accelerate requests regex bitsandbytes peft"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:42:17.372895Z","iopub.status.busy":"2024-05-24T12:42:17.372114Z","iopub.status.idle":"2024-05-24T12:42:18.116202Z","shell.execute_reply":"2024-05-24T12:42:18.115197Z","shell.execute_reply.started":"2024-05-24T12:42:17.372859Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import torch\n","import logging\n","import warnings\n","from typing import Dict, List\n","from datasets import Dataset, load_dataset, disable_caching\n","disable_caching() ## disable huggingface cache\n","from torch.utils.data import Dataset\n","from IPython.display import Markdown\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from functools import partial\n","import copy\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","torch.manual_seed(42)\n","from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel, pipeline, AutoModelForCausalLM, AutoTokenizer, DataCollatorForSeq2Seq, AdamW, get_linear_schedule_with_warmup, TrainingArguments, Trainer\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training \n","import bitsandbytes\n","import nltk\n","\n","nltk.download('punkt')\n","\n","logging.getLogger().setLevel(logging.CRITICAL)\n","\n","warnings.filterwarnings('ignore')\n","\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:42:21.510746Z","iopub.status.busy":"2024-05-24T12:42:21.509835Z","iopub.status.idle":"2024-05-24T12:42:21.517204Z","shell.execute_reply":"2024-05-24T12:42:21.516234Z","shell.execute_reply.started":"2024-05-24T12:42:21.510711Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:42:23.383404Z","iopub.status.busy":"2024-05-24T12:42:23.383006Z","iopub.status.idle":"2024-05-24T12:42:24.459790Z","shell.execute_reply":"2024-05-24T12:42:24.458692Z","shell.execute_reply.started":"2024-05-24T12:42:23.383376Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri May 24 12:42:24 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n","| N/A   48C    P8              11W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:42:41.009991Z","iopub.status.busy":"2024-05-24T12:42:41.009605Z","iopub.status.idle":"2024-05-24T12:42:41.988339Z","shell.execute_reply":"2024-05-24T12:42:41.987397Z","shell.execute_reply.started":"2024-05-24T12:42:41.009957Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Mon_Apr__3_17:16:06_PDT_2023\n","Cuda compilation tools, release 12.1, V12.1.105\n","Build cuda_12.1.r12.1/compiler.32688072_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"markdown","metadata":{},"source":["# **Dataset Preparation**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:42:43.633272Z","iopub.status.busy":"2024-05-24T12:42:43.632883Z","iopub.status.idle":"2024-05-24T12:42:48.120664Z","shell.execute_reply":"2024-05-24T12:42:48.119778Z","shell.execute_reply.started":"2024-05-24T12:42:43.633239Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7dff821f29bb4c698aa7037d13059223","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/7.80k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Downloading data: 100%|██████████| 15.9M/15.9M [00:00<00:00, 22.8MB/s]\n","Downloading data: 100%|██████████| 813k/813k [00:00<00:00, 3.24MB/s]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec90b08fe7bf4b51a2ed0def69bae402","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/35331 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b38a7fd673e4efe97517df84cc2c97f","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/1789 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['prompt', 'response', 'helpfulness', 'correctness', 'coherence', 'complexity', 'verbosity'],\n","    num_rows: 200\n","})\n","{'prompt': 'What are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs?', 'response': \"To build an assistive device to help an elderly person with basic needs, one must consider three crucial things: safety, compatibility, and ease of use. Safety is paramount, as the device must not cause harm to the user. Compatibility with the user's environment and other devices is also essential. Finally, the device must be simple enough for the elderly person to operate.\", 'helpfulness': 3, 'correctness': 4, 'coherence': 4, 'complexity': 2, 'verbosity': 2}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6075a13da206426d92b3cd9728075f19","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/200 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'prompt': 'Below is an instruction that describes a task. Write a response that appropriately completes the request. Instruction: What are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs?\\n Response:', 'response': \"To build an assistive device to help an elderly person with basic needs, one must consider three crucial things: safety, compatibility, and ease of use. Safety is paramount, as the device must not cause harm to the user. Compatibility with the user's environment and other devices is also essential. Finally, the device must be simple enough for the elderly person to operate.\", 'helpfulness': 3, 'correctness': 4, 'coherence': 4, 'complexity': 2, 'verbosity': 2, 'answer': \"To build an assistive device to help an elderly person with basic needs, one must consider three crucial things: safety, compatibility, and ease of use. Safety is paramount, as the device must not cause harm to the user. Compatibility with the user's environment and other devices is also essential. Finally, the device must be simple enough for the elderly person to operate.\", 'text': \"Below is an instruction that describes a task. Write a response that appropriately completes the request. Instruction: What are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs?\\n Response:To build an assistive device to help an elderly person with basic needs, one must consider three crucial things: safety, compatibility, and ease of use. Safety is paramount, as the device must not cause harm to the user. Compatibility with the user's environment and other devices is also essential. Finally, the device must be simple enough for the elderly person to operate.\"}\n"]}],"source":["dataset = load_dataset(\"nvidia/HelpSteer\" , split = 'train') \n","small_dataset = dataset.select([i for i in range(200)])\n","print(small_dataset)\n","print(small_dataset[0])\n","\n","# creating templates\n","prompt_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request. Instruction: {instruction}\\n Response:\"\"\"\n","answer_template = \"\"\"{response}\"\"\"\n","\n","# creating function to add keys in the dictionary for prompt, answer and whole text\n","def _add_text(rec):\n","    instruction = rec[\"prompt\"]\n","    response = rec[\"response\"] \n","    # check if both exists, else raise error   \n","    if not instruction:\n","        raise ValueError(f\"Expected an instruction in: {rec}\")\n","    if not response:\n","        raise ValueError(f\"Expected a response in: {rec}\")\n","    rec[\"prompt\"] = prompt_template.format(instruction=instruction)\n","    rec[\"answer\"] = answer_template.format(response=response)\n","    rec[\"text\"] = rec[\"prompt\"] + rec[\"answer\"]\n","    return rec\n","\n","# running through all samples\n","small_dataset = small_dataset.map(_add_text)\n","print(small_dataset[0])"]},{"cell_type":"markdown","metadata":{},"source":["# **Model**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T13:14:17.250056Z","iopub.status.busy":"2024-05-24T13:14:17.249316Z","iopub.status.idle":"2024-05-24T13:14:25.367737Z","shell.execute_reply":"2024-05-24T13:14:25.366681Z","shell.execute_reply.started":"2024-05-24T13:14:17.250013Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"]},{"name":"stdout","output_type":"stream","text":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50257, 1600)\n","    (wpe): Embedding(1024, 1600)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-47): 48 x GPT2Block(\n","        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Linear8bitLt(in_features=1600, out_features=4800, bias=True)\n","          (c_proj): Linear8bitLt(in_features=1600, out_features=1600, bias=True)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Linear8bitLt(in_features=1600, out_features=6400, bias=True)\n","          (c_proj): Linear8bitLt(in_features=6400, out_features=1600, bias=True)\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",")\n"]}],"source":["# loading the tokenizer for dolly model. The tokenizer converts raw text into tokens\n","model_id = \"openai-community/gpt2-xl\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_id)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","#loading the model using AutoModelForCausalLM\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    device_map=\"auto\",\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16\n",")\n","\n","# resizes input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n","model.resize_token_embeddings(len(tokenizer))\n","print(model)"]},{"cell_type":"markdown","metadata":{},"source":["# **splitting dataset**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T13:15:59.127110Z","iopub.status.busy":"2024-05-24T13:15:59.126278Z","iopub.status.idle":"2024-05-24T13:16:03.040396Z","shell.execute_reply":"2024-05-24T13:16:03.039499Z","shell.execute_reply.started":"2024-05-24T13:15:59.127068Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3827eaf10c9543a2a09eb9828f82a9fc","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/200 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1b9fc0ca665423bbcf6469df4367b6d","version_major":2,"version_minor":0},"text/plain":["Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 186\n","    })\n","    test: Dataset({\n","        features: ['text', 'input_ids', 'attention_mask', 'labels'],\n","        num_rows: 14\n","    })\n","})\n"]}],"source":["MAX_LENGTH = 256\n","\n","# Function to generate token embeddings from text part of batch\n","def _preprocess_batch(batch: Dict[str, List]):  \n","    model_inputs = tokenizer(batch[\"text\"], max_length=MAX_LENGTH, truncation=True, padding='max_length')    \n","    model_inputs[\"labels\"] = copy.deepcopy(model_inputs['input_ids'])\n","    return model_inputs\n","\n","_preprocessing_function = partial(_preprocess_batch)\n","\n","# apply the preprocessing function to each batch in the dataset\n","encoded_small_dataset = small_dataset.map(\n","        _preprocessing_function,\n","        batched=True,\n","        remove_columns=[\"helpfulness\", \"response\", \"prompt\", \"answer\", \"verbosity\", \"complexity\", \"coherence\", \"correctness\"],\n",")\n","processed_dataset = encoded_small_dataset.filter(lambda rec: len(rec[\"input_ids\"]) <= MAX_LENGTH)\n","\n","# splitting dataset\n","split_dataset = processed_dataset.train_test_split(test_size=14, seed=0)\n","print(split_dataset)\n","\n","# takes a list of samples from a Dataset and collate them into a batch, as a dictionary of PyTorch tensors.\n","data_collator = DataCollatorForSeq2Seq(\n","        model = model, tokenizer=tokenizer, max_length=MAX_LENGTH, pad_to_multiple_of=8, padding='max_length')\n"]},{"cell_type":"markdown","metadata":{},"source":["# **LoRA Config**"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T13:16:04.671944Z","iopub.status.busy":"2024-05-24T13:16:04.671575Z","iopub.status.idle":"2024-05-24T13:16:05.652516Z","shell.execute_reply":"2024-05-24T13:16:05.651552Z","shell.execute_reply.started":"2024-05-24T13:16:04.671914Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 78,643,200 || all params: 1,636,254,400 || trainable%: 4.8063\n"]}],"source":["LORA_R = 256 # 512\n","LORA_ALPHA = 512 # 1024\n","LORA_DROPOUT = 0.05\n","\n","lora_config = LoraConfig(\n","                 r = LORA_R, # the dimension of the low-rank matrices\n","                 lora_alpha = LORA_ALPHA, # scaling factor for the weight matrices\n","                 lora_dropout = LORA_DROPOUT, # dropout probability of the LoRA layers\n","                 bias=\"none\",\n","                 task_type=\"CAUSAL_LM\",\n","                 target_modules=None ,\n",")\n","\n","# Prepare int-8 model for training - utility function that prepares a PyTorch model for int8 quantization training. <https://huggingface.co/docs/peft/task_guides/int8-asr>\n","model = prepare_model_for_kbit_training (model)\n","# initialize the model with the LoRA framework\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()"]},{"cell_type":"markdown","metadata":{},"source":["# **training arguments**"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T13:16:11.879714Z","iopub.status.busy":"2024-05-24T13:16:11.879056Z","iopub.status.idle":"2024-05-24T13:49:03.830809Z","shell.execute_reply":"2024-05-24T13:49:03.829728Z","shell.execute_reply.started":"2024-05-24T13:16:11.879679Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240524_131655-zk1suh5h</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/lonewolf-ent/huggingface/runs/zk1suh5h' target=\"_blank\">major-salad-1</a></strong> to <a href='https://wandb.ai/lonewolf-ent/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/lonewolf-ent/huggingface' target=\"_blank\">https://wandb.ai/lonewolf-ent/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/lonewolf-ent/huggingface/runs/zk1suh5h' target=\"_blank\">https://wandb.ai/lonewolf-ent/huggingface/runs/zk1suh5h</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1860' max='1860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1860/1860 31:46, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.128800</td>\n","      <td>2.000298</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.191000</td>\n","      <td>1.579270</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.702600</td>\n","      <td>1.302359</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.430400</td>\n","      <td>1.168633</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.280400</td>\n","      <td>1.063657</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.196800</td>\n","      <td>1.016190</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.147400</td>\n","      <td>1.006593</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.119400</td>\n","      <td>1.012021</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.099300</td>\n","      <td>1.018030</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.089000</td>\n","      <td>1.021354</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["EPOCHS = 10\n","LEARNING_RATE = 1e-4  \n","MODEL_SAVE_FOLDER_NAME = \"fine-tuned-gpt-2\"\n","training_args = TrainingArguments(\n","                    output_dir=MODEL_SAVE_FOLDER_NAME,\n","                    overwrite_output_dir=True,\n","                    fp16=True,\n","                    per_device_train_batch_size=1,\n","                    per_device_eval_batch_size=1,\n","                    learning_rate=LEARNING_RATE,\n","                    num_train_epochs=EPOCHS,\n","                    logging_strategy=\"epoch\",\n","                    evaluation_strategy=\"epoch\",\n","                    save_strategy=\"epoch\",\n",")\n","# training the model \n","trainer = Trainer(\n","        model=model,\n","        tokenizer=tokenizer,\n","        args=training_args,\n","        train_dataset=split_dataset['train'],\n","        eval_dataset=split_dataset[\"test\"],\n","        data_collator=data_collator,\n",")\n","model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","trainer.train()\n","# only saves the incremental 🤗 PEFT weights (adapter_model.bin) that were trained, meaning it is super efficient to store, transfer, and load.\n","trainer.model.save_pretrained(MODEL_SAVE_FOLDER_NAME)\n","# save the full model and the training arguments\n","trainer.save_model(MODEL_SAVE_FOLDER_NAME)\n","trainer.model.config.save_pretrained(MODEL_SAVE_FOLDER_NAME)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:16:00.428977Z","iopub.status.busy":"2024-05-24T14:16:00.428148Z","iopub.status.idle":"2024-05-24T14:16:41.101412Z","shell.execute_reply":"2024-05-24T14:16:41.100308Z","shell.execute_reply.started":"2024-05-24T14:16:00.428940Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"]},{"data":{"text/plain":["\"You can create an assistant device to help an elderly person with basic needs by using various technologies, such as AI, machine learning, and natural language processing. The three most important things to consider when deciding what technology to use are:\\n\\n1. Accurate: The technology should be accurate enough to help the elderly person with their needs. If the technology is inaccurate, the elderly person may not be able to properly use it and may need to contact the company for repairs or replacements.\\n\\n2. Reliable: The technology should be reliable enough to do the job it is meant to do. If the technology fails or stops working, the elderly person shouldn't have to contact the company for repairs or replacements.\\n\\n3. Efficient: The technology should be efficient enough to do the job it is meant to do. The elderly person should be able to use the technology without wasting time or resources.\""]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Function to format the response and filter out the instruction from the response.\n","def postprocess(response):\n","    messages = response.split(\"Response:\")\n","    if not messages:\n","        raise ValueError(\"Invalid template for prompt. The template should include the term 'Response:'\")\n","    return \"\".join(messages[1:])\n","# Prompt for prediction\n","inference_prompt = \"What are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs?\"\n","# Inference pipeline with the fine-tuned model\n","inf_pipeline =  pipeline('text-generation', model=trainer.model, tokenizer=tokenizer, max_length=256, trust_remote_code=True)\n","# Format the prompt using the `prompt_template` and generate response \n","response = inf_pipeline(prompt_template.format(instruction=inference_prompt))[0]['generated_text']\n","# postprocess the response\n","formatted_response = postprocess(response)\n","formatted_response"]},{"cell_type":"markdown","metadata":{},"source":["# **Training stats**"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:29:06.232802Z","iopub.status.busy":"2024-05-24T14:29:06.232055Z","iopub.status.idle":"2024-05-24T14:29:06.240961Z","shell.execute_reply":"2024-05-24T14:29:06.239849Z","shell.execute_reply.started":"2024-05-24T14:29:06.232768Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","        <iframe\n","            width=\"1080\"\n","            height=\"1000\"\n","            src=\"https://api.wandb.ai/links/lonewolf-ent/cct8dzpz\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x78d124a4e5f0>"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import IFrame\n","IFrame('https://api.wandb.ai/links/lonewolf-ent/cct8dzpz', width=1080, height=1000)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
