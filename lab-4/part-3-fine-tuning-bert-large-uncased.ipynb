{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Video_Games.json.gz","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:37:43.490718Z","iopub.execute_input":"2024-05-24T16:37:43.491479Z","iopub.status.idle":"2024-05-24T16:37:52.932520Z","shell.execute_reply.started":"2024-05-24T16:37:43.491442Z","shell.execute_reply":"2024-05-24T16:37:52.931272Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"--2024-05-24 16:37:44--  https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Video_Games.json.gz\nResolving datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)... 132.239.8.30\nConnecting to datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)|132.239.8.30|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 522823613 (499M) [application/x-gzip]\nSaving to: 'Video_Games.json.gz.1'\n\nVideo_Games.json.gz  25%[====>               ] 129.24M  10.5MB/s    eta 22s    ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers datasets accelerate requests regex bitsandbytes peft","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:37:52.934684Z","iopub.execute_input":"2024-05-24T16:37:52.935026Z","iopub.status.idle":"2024-05-24T16:38:05.399405Z","shell.execute_reply.started":"2024-05-24T16:37:52.934994Z","shell.execute_reply":"2024-05-24T16:38:05.398294Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (2023.12.25)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.11.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.2.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport logging\nimport warnings\nfrom typing import Dict, List\nfrom datasets import Dataset, load_dataset, disable_caching\ndisable_caching() ## disable huggingface cache\nfrom torch.utils.data import Dataset, Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\nfrom IPython.display import Markdown\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom functools import partial\nimport copy\nfrom transformers import BertTokenizer, BertModel, pipeline, AutoModelForQuestionAnswering, AutoModelForCausalLM, AutoTokenizer, DefaultDataCollator, DataCollatorForSeq2Seq, AdamW, get_linear_schedule_with_warmup, TrainingArguments, Trainer\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nimport os\nimport bitsandbytes\nimport nltk\nimport gzip\nimport json\nimport pandas as pd\nimport numpy as np\n\nnltk.download('punkt')\n\nlogging.getLogger().setLevel(logging.CRITICAL)\n\nwarnings.filterwarnings('ignore')\n\nif torch.cuda.is_available():\n  device = torch.device(\"cuda\")\nelse:\n  device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:38:05.401065Z","iopub.execute_input":"2024-05-24T16:38:05.401790Z","iopub.status.idle":"2024-05-24T16:38:05.555229Z","shell.execute_reply.started":"2024-05-24T16:38:05.401747Z","shell.execute_reply":"2024-05-24T16:38:05.554317Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"def parse(path):\n  g = gzip.open(path, 'rb')\n  for l in g:\n    yield json.loads(l)\n\ndef getDF(path):\n  i = 0\n  df = {}\n  for d in parse(path):\n    df[i] = d\n    i += 1\n  return pd.DataFrame.from_dict(df, orient='index')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-24T16:38:05.557322Z","iopub.execute_input":"2024-05-24T16:38:05.557629Z","iopub.status.idle":"2024-05-24T16:38:05.563217Z","shell.execute_reply.started":"2024-05-24T16:38:05.557605Z","shell.execute_reply":"2024-05-24T16:38:05.562377Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df = getDF('/kaggle/working/Video_Games.json.gz')\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:38:05.564206Z","iopub.execute_input":"2024-05-24T16:38:05.564447Z","iopub.status.idle":"2024-05-24T16:39:15.290514Z","shell.execute_reply.started":"2024-05-24T16:38:05.564418Z","shell.execute_reply":"2024-05-24T16:39:15.289569Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"         overall  verified   reviewTime      reviewerID        asin  \\\n0            1.0      True   06 9, 2014  A21ROB4YDOZA5P  0439381673   \n1            3.0      True  05 10, 2014  A3TNZ2Q5E7HTHD  0439381673   \n2            4.0      True   02 7, 2014  A1OKRM3QFEATQO  0439381673   \n3            1.0      True   02 7, 2014  A2XO1JFCNEYV3T  0439381673   \n4            4.0      True  01 16, 2014  A19WLPIRHD15TH  0439381673   \n...          ...       ...          ...             ...         ...   \n2565344      5.0      True   08 1, 2018   ANGB54K3888S4  B01HJEBIAA   \n2565345      5.0      True  07 17, 2018  A3TEVKR0ZVQB2T  B01HJEBIAA   \n2565346      5.0      True   07 6, 2018   ABE7YPWEHNVJZ  B01HJEBIAA   \n2565347      5.0      True  06 12, 2018  A3ES9QBK3G192O  B01HJEBIAA   \n2565348      5.0      True  04 19, 2018  A194UPGR3OXZB7  B01HJEBIAA   \n\n             reviewerName                                         reviewText  \\\n0           Mary M. Clark  I used to play this game years ago and loved i...   \n1               Sarabatya  The game itself worked great but the story lin...   \n2         Amazon Customer  I had to learn the hard way after ordering thi...   \n3        ColoradoPartyof5  The product description should state this clea...   \n4          Karen Robinson  I would recommend this learning game for anyon...   \n...                   ...                                                ...   \n2565344              josh                                 Love it, work good   \n2565345      Prime Member  I do a lot of copy/paste and other keyboard sh...   \n2565346   Amazon Customer  One year in and it's still working great!  Hig...   \n2565347   Lina Marmolejos                                          EXCELENTE   \n2565348             Kayla  Haven't really used it too much but dang this ...   \n\n                                                   summary  unixReviewTime  \\\n0                                        Did not like this      1402272000   \n1                                           Almost Perfect      1399680000   \n2        DOES NOT WORK WITH MAC OS unless it is 10.3 or...      1391731200   \n3                                 does not work on Mac OSX      1391731200   \n4                                              Roughing it      1389830400   \n...                                                    ...             ...   \n2565344                                         Works good      1533081600   \n2565345                    Great mouse for work and gaming      1531785600   \n2565346                                         Five Stars      1530835200   \n2565347                                         Five Stars      1528761600   \n2565348                              Gorgeous and durable!      1524096000   \n\n        vote style                                              image  \n0        NaN   NaN                                                NaN  \n1        NaN   NaN                                                NaN  \n2         15   NaN                                                NaN  \n3         11   NaN                                                NaN  \n4        NaN   NaN                                                NaN  \n...      ...   ...                                                ...  \n2565344  NaN   NaN                                                NaN  \n2565345  NaN   NaN  [https://images-na.ssl-images-amazon.com/image...  \n2565346  NaN   NaN                                                NaN  \n2565347  NaN   NaN                                                NaN  \n2565348  NaN   NaN                                                NaN  \n\n[2565349 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>verified</th>\n      <th>reviewTime</th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>reviewText</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>vote</th>\n      <th>style</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>True</td>\n      <td>06 9, 2014</td>\n      <td>A21ROB4YDOZA5P</td>\n      <td>0439381673</td>\n      <td>Mary M. Clark</td>\n      <td>I used to play this game years ago and loved i...</td>\n      <td>Did not like this</td>\n      <td>1402272000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>True</td>\n      <td>05 10, 2014</td>\n      <td>A3TNZ2Q5E7HTHD</td>\n      <td>0439381673</td>\n      <td>Sarabatya</td>\n      <td>The game itself worked great but the story lin...</td>\n      <td>Almost Perfect</td>\n      <td>1399680000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>True</td>\n      <td>02 7, 2014</td>\n      <td>A1OKRM3QFEATQO</td>\n      <td>0439381673</td>\n      <td>Amazon Customer</td>\n      <td>I had to learn the hard way after ordering thi...</td>\n      <td>DOES NOT WORK WITH MAC OS unless it is 10.3 or...</td>\n      <td>1391731200</td>\n      <td>15</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>True</td>\n      <td>02 7, 2014</td>\n      <td>A2XO1JFCNEYV3T</td>\n      <td>0439381673</td>\n      <td>ColoradoPartyof5</td>\n      <td>The product description should state this clea...</td>\n      <td>does not work on Mac OSX</td>\n      <td>1391731200</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>True</td>\n      <td>01 16, 2014</td>\n      <td>A19WLPIRHD15TH</td>\n      <td>0439381673</td>\n      <td>Karen Robinson</td>\n      <td>I would recommend this learning game for anyon...</td>\n      <td>Roughing it</td>\n      <td>1389830400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2565344</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>08 1, 2018</td>\n      <td>ANGB54K3888S4</td>\n      <td>B01HJEBIAA</td>\n      <td>josh</td>\n      <td>Love it, work good</td>\n      <td>Works good</td>\n      <td>1533081600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2565345</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>07 17, 2018</td>\n      <td>A3TEVKR0ZVQB2T</td>\n      <td>B01HJEBIAA</td>\n      <td>Prime Member</td>\n      <td>I do a lot of copy/paste and other keyboard sh...</td>\n      <td>Great mouse for work and gaming</td>\n      <td>1531785600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n    </tr>\n    <tr>\n      <th>2565346</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>07 6, 2018</td>\n      <td>ABE7YPWEHNVJZ</td>\n      <td>B01HJEBIAA</td>\n      <td>Amazon Customer</td>\n      <td>One year in and it's still working great!  Hig...</td>\n      <td>Five Stars</td>\n      <td>1530835200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2565347</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>06 12, 2018</td>\n      <td>A3ES9QBK3G192O</td>\n      <td>B01HJEBIAA</td>\n      <td>Lina Marmolejos</td>\n      <td>EXCELENTE</td>\n      <td>Five Stars</td>\n      <td>1528761600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2565348</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>04 19, 2018</td>\n      <td>A194UPGR3OXZB7</td>\n      <td>B01HJEBIAA</td>\n      <td>Kayla</td>\n      <td>Haven't really used it too much but dang this ...</td>\n      <td>Gorgeous and durable!</td>\n      <td>1524096000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2565349 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:15.291890Z","iopub.execute_input":"2024-05-24T16:39:15.292275Z","iopub.status.idle":"2024-05-24T16:39:15.298408Z","shell.execute_reply.started":"2024-05-24T16:39:15.292239Z","shell.execute_reply":"2024-05-24T16:39:15.297552Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"Index(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin',\n       'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote',\n       'style', 'image'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(['verified', 'reviewTime', 'reviewerID', 'asin', 'reviewerName', 'summary', 'unixReviewTime', 'vote', 'style', 'image'], axis=1, inplace=True)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:15.299807Z","iopub.execute_input":"2024-05-24T16:39:15.300461Z","iopub.status.idle":"2024-05-24T16:39:16.436292Z","shell.execute_reply.started":"2024-05-24T16:39:15.300425Z","shell.execute_reply":"2024-05-24T16:39:16.435301Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"         overall                                         reviewText\n0            1.0  I used to play this game years ago and loved i...\n1            3.0  The game itself worked great but the story lin...\n2            4.0  I had to learn the hard way after ordering thi...\n3            1.0  The product description should state this clea...\n4            4.0  I would recommend this learning game for anyon...\n...          ...                                                ...\n2565344      5.0                                 Love it, work good\n2565345      5.0  I do a lot of copy/paste and other keyboard sh...\n2565346      5.0  One year in and it's still working great!  Hig...\n2565347      5.0                                          EXCELENTE\n2565348      5.0  Haven't really used it too much but dang this ...\n\n[2565349 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>I used to play this game years ago and loved i...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>The game itself worked great but the story lin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>I had to learn the hard way after ordering thi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>The product description should state this clea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>I would recommend this learning game for anyon...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2565344</th>\n      <td>5.0</td>\n      <td>Love it, work good</td>\n    </tr>\n    <tr>\n      <th>2565345</th>\n      <td>5.0</td>\n      <td>I do a lot of copy/paste and other keyboard sh...</td>\n    </tr>\n    <tr>\n      <th>2565346</th>\n      <td>5.0</td>\n      <td>One year in and it's still working great!  Hig...</td>\n    </tr>\n    <tr>\n      <th>2565347</th>\n      <td>5.0</td>\n      <td>EXCELENTE</td>\n    </tr>\n    <tr>\n      <th>2565348</th>\n      <td>5.0</td>\n      <td>Haven't really used it too much but dang this ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2565349 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def read_and_shuffle(df):\n    # Random shuffle.\n    df.sample(frac=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.437646Z","iopub.execute_input":"2024-05-24T16:39:16.437955Z","iopub.status.idle":"2024-05-24T16:39:16.442825Z","shell.execute_reply.started":"2024-05-24T16:39:16.437929Z","shell.execute_reply":"2024-05-24T16:39:16.441766Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class AmazonReviewsDataset(Dataset):\n    def __init__(self, df, maxlen):\n        self.df = df\n        # A reset reindexes from 1 to len(df), the shuffled df frames are sparse.\n        self.df.reset_index(drop=True, inplace=True)\n        self.tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n        self.maxlen = maxlen\n\n    def __len__(self):\n        return(len(self.df))\n\n    def __getitem__(self, index):\n        review = self.df.loc[index, 'reviewText']\n\n        # Classes start from 0.\n        label = int(self.df.loc[index, 'overall']) - 1\n\n        # Use BERT tokenizer since it needs to be able to match the tokens to the pre trained words.\n        tokens = self.tokenizer.tokenize(review)\n\n        # BERT inputs typically start with a '[CLS]' tag and end with a '[SEP]' tag. For\n        tokens = ['[CLS]'] + tokens + ['[SEP]']\n\n        if len(tokens) < self.maxlen:\n            # Add the ['PAD'] token\n            tokens = tokens + ['[PAD]' for item in range(self.maxlen-len(tokens))]\n        else:\n            # Truncate the tokens at maxLen - 1 and add a '[SEP]' tag.\n            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n\n        # BERT tokenizer converts the string tokens to their respective IDs.\n        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n\n        # Converting to pytorch tensors.\n        tokens_ids_tensor = torch.tensor(token_ids)\n\n        # Masks place a 1 if token != PAD else a 0.\n        attn_mask = (tokens_ids_tensor != 0).long()\n\n        return tokens_ids_tensor, attn_mask, label","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.444162Z","iopub.execute_input":"2024-05-24T16:39:16.444443Z","iopub.status.idle":"2024-05-24T16:39:16.456876Z","shell.execute_reply.started":"2024-05-24T16:39:16.444419Z","shell.execute_reply":"2024-05-24T16:39:16.456066Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def get_train_and_val_split(df, splitRatio=0.8):\n    train=df.sample(frac=splitRatio,random_state=200)\n    val=df.drop(train.index)\n    print(\"Number of Training Samples: \", len(train))\n    print(\"Number of Validation Samples: \", len(val))\n    return(train, val)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.460098Z","iopub.execute_input":"2024-05-24T16:39:16.460449Z","iopub.status.idle":"2024-05-24T16:39:16.472223Z","shell.execute_reply.started":"2024-05-24T16:39:16.460419Z","shell.execute_reply":"2024-05-24T16:39:16.471390Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def get_max_length(reviews):\n    return len(max(reviews, key=len))","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.473325Z","iopub.execute_input":"2024-05-24T16:39:16.473686Z","iopub.status.idle":"2024-05-24T16:39:16.481200Z","shell.execute_reply.started":"2024-05-24T16:39:16.473656Z","shell.execute_reply":"2024-05-24T16:39:16.480329Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def get_accuracy(logits, labels):\n    # get the index of the max value in the row.\n    predictedClass = logits.max(dim = 1)[1]\n\n    # get accuracy by averaging over entire batch.\n    acc = (predictedClass == labels).float().mean()\n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.482376Z","iopub.execute_input":"2024-05-24T16:39:16.482672Z","iopub.status.idle":"2024-05-24T16:39:16.491369Z","shell.execute_reply.started":"2024-05-24T16:39:16.482648Z","shell.execute_reply":"2024-05-24T16:39:16.490682Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def trainFunc(net, loss_func, opti, train_loader, test_loader, config):\n    best_acc = 0\n    for ep in range(config[\"epochs\"]):\n        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n            opti.zero_grad()\n            #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n\n            logits = net(seq, attn_masks)\n            loss = loss_func(m(logits), labels)\n\n            loss.backward()\n            opti.step()\n            print(\"Iteration: \", it+1)\n\n            if (it + 1) % config[\"printEvery\"] == 0:\n                acc = get_accuracy(m(logits), labels)\n                if not os.path.exists(config[\"outputFolder\"]):\n                    os.makedirs(config[\"outputFolder\"])\n\n                # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n                torch.save(net.state_dict(), os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"]))\n                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n                print(\"Saving at\", os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"]))\n\n        # perform validation at the end of an epoch.\n        val_acc, val_loss = evaluate(net, loss_func, val_loader, config)\n        print(\" Validation Accuracy : {}, Validation Loss : {}\".format(val_acc, val_loss))\n        if val_acc > best_acc:\n            print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n            best_acc = val_acc\n            torch.save(net.state_dict(), os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"] + \"_valTested_\" + str(best_acc)))\n     ","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.492735Z","iopub.execute_input":"2024-05-24T16:39:16.493297Z","iopub.status.idle":"2024-05-24T16:39:16.508510Z","shell.execute_reply.started":"2024-05-24T16:39:16.493266Z","shell.execute_reply":"2024-05-24T16:39:16.507664Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def evaluate(net, loss_func, dataloader, config):\n    net.eval()\n\n    mean_acc, mean_loss = 0, 0\n    count = 0\n\n    with torch.no_grad():\n        for seq, attn_masks, labels in dataloader:\n            #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n\n            logits = net(seq, attn_masks)\n            mean_loss += loss_func(m(logits), labels)\n            mean_acc += get_accuracy(m(logits), labels)\n            print(\"Validation iteration\", count+1)\n            count += 1\n\n            '''\n            The entire validation set was around 0.1 million entries,\n            the validationFraction param controls what fraction of the shuffled\n            validation set you want to validate the results on.\n            '''\n            if count > config[\"validationFraction\"] * len(val_set):\n                break\n    return mean_acc / count, mean_loss / count","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.509443Z","iopub.execute_input":"2024-05-24T16:39:16.509787Z","iopub.status.idle":"2024-05-24T16:39:16.522200Z","shell.execute_reply.started":"2024-05-24T16:39:16.509764Z","shell.execute_reply":"2024-05-24T16:39:16.521383Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"splitRatio\" : 0.8,\n    \"maxLength\" : 100,\n    \"printEvery\" : 100,\n    \"outputFolder\" : \"Models\",\n    \"outputFileName\" : \"AmazonReviewClassifier.dat\",\n    \"threads\" : 4,\n    \"batchSize\" : 64,\n    \"validationFraction\" : 0.0005,\n    \"epochs\" : 5,\n    \"forceCPU\" : False\n    }\n\nconfig[\"device\"] = device","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.523218Z","iopub.execute_input":"2024-05-24T16:39:16.523468Z","iopub.status.idle":"2024-05-24T16:39:16.538424Z","shell.execute_reply.started":"2024-05-24T16:39:16.523446Z","shell.execute_reply":"2024-05-24T16:39:16.537544Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"class SentimentClassifier(nn.Module):\n    def __init__(self, num_classes, device, freeze_bert = True):\n        super(SentimentClassifier, self).__init__()\n        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n        self.device = device\n\n        if freeze_bert:\n            for p in self.bert_layer.parameters():\n                p.requires_grad = False\n\n        self.cls_layer = nn.Linear(768, num_classes)\n\n    def forward(self, seq, attn_masks):\n        '''\n        Inputs:\n            -seq : Tensor of shape [B, T] containing token ids of sequences\n            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n        '''\n\n        #Feeding the input to BERT model to obtain contextualized representations\n        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n\n        #Obtaining the representation of [CLS] head\n        cls_rep = cont_reps[:, 0]\n\n        #Feeding cls_rep to the classifier layer\n        logits = self.cls_layer(cls_rep)\n\n        return logits.to(self.device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.539465Z","iopub.execute_input":"2024-05-24T16:39:16.539734Z","iopub.status.idle":"2024-05-24T16:39:16.550464Z","shell.execute_reply.started":"2024-05-24T16:39:16.539706Z","shell.execute_reply":"2024-05-24T16:39:16.549662Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print('Loading BERT tokenizer...')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n\nprint(\"Configuration is: \", config)\n\ndf = read_and_shuffle(df)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:16.551469Z","iopub.execute_input":"2024-05-24T16:39:16.551805Z","iopub.status.idle":"2024-05-24T16:39:17.267990Z","shell.execute_reply.started":"2024-05-24T16:39:16.551783Z","shell.execute_reply":"2024-05-24T16:39:17.266964Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Loading BERT tokenizer...\nConfiguration is:  {'splitRatio': 0.8, 'maxLength': 100, 'printEvery': 100, 'outputFolder': 'Models', 'outputFileName': 'AmazonReviewClassifier.dat', 'threads': 4, 'batchSize': 64, 'validationFraction': 0.0005, 'epochs': 5, 'forceCPU': False, 'device': device(type='cuda')}\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"         overall                                         reviewText\n0            1.0  I used to play this game years ago and loved i...\n1            3.0  The game itself worked great but the story lin...\n2            4.0  I had to learn the hard way after ordering thi...\n3            1.0  The product description should state this clea...\n4            4.0  I would recommend this learning game for anyon...\n...          ...                                                ...\n2565344      5.0                                 Love it, work good\n2565345      5.0  I do a lot of copy/paste and other keyboard sh...\n2565346      5.0  One year in and it's still working great!  Hig...\n2565347      5.0                                          EXCELENTE\n2565348      5.0  Haven't really used it too much but dang this ...\n\n[2565349 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>I used to play this game years ago and loved i...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>The game itself worked great but the story lin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>I had to learn the hard way after ordering thi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>The product description should state this clea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>I would recommend this learning game for anyon...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2565344</th>\n      <td>5.0</td>\n      <td>Love it, work good</td>\n    </tr>\n    <tr>\n      <th>2565345</th>\n      <td>5.0</td>\n      <td>I do a lot of copy/paste and other keyboard sh...</td>\n    </tr>\n    <tr>\n      <th>2565346</th>\n      <td>5.0</td>\n      <td>One year in and it's still working great!  Hig...</td>\n    </tr>\n    <tr>\n      <th>2565347</th>\n      <td>5.0</td>\n      <td>EXCELENTE</td>\n    </tr>\n    <tr>\n      <th>2565348</th>\n      <td>5.0</td>\n      <td>Haven't really used it too much but dang this ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2565349 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"num_classes = df['overall'].nunique()\nprint(\"Number of Target Output Classes:\", num_classes)\ntotalDatasetSize = len(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:39:38.931629Z","iopub.execute_input":"2024-05-24T16:39:38.932378Z","iopub.status.idle":"2024-05-24T16:39:38.967619Z","shell.execute_reply.started":"2024-05-24T16:39:38.932342Z","shell.execute_reply":"2024-05-24T16:39:38.966675Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Number of Target Output Classes: 5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Group by the column overall. This helps you get distribution of the Review overalls.\nsymbols = df.groupby('overall')\n\noveralls_dist = []\nfor i in range(num_classes):\n    overalls_dist.append(len(symbols.groups[i+1])/totalDatasetSize)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T16:40:16.497874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, val = get_train_and_val_split(df, config[\"splitRatio\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"T = config[\"maxLength\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = AmazonReviewsDataset(train, T)\nval_set = AmazonReviewsDataset(val, T)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])\nval_loader = DataLoader(val_set, batch_size = config[\"batchSize\"], num_workers = config[\"threads\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We are unfreezing the BERT layers so as to be able to fine tune and save a new BERT model that is specific to the Sizeable food reviews dataset.\n\nnet = SentimentClassifier(num_classes, config[\"device\"], freeze_bert=False)\nnet.to(config[\"device\"])\nweights = torch.tensor(overalls_dist).to(config[\"device\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the Loss function and Optimizer.\nloss_func = nn.NLLLoss(weight=weights)\nopti = optim.Adam(net.parameters(), lr = 2e-5)\nm = nn.LogSoftmax(dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.set_device(0)\ntrainFunc(net, loss_func, opti, train_loader, val_loader, config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DefaultDataCollator()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''trainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_datasets[\"train\"].select(range(1000)),\n    eval_dataset=tokenized_datasets[\"validation\"].select(range(100)),\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''trainer.train()'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}